{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(1, '../')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "import keras\n",
    "import numpy as np\n",
    "from data_preparation import *\n",
    "from utils import *\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers.core import Dense, Flatten\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import *\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from attention import AttentionLayer\n",
    "from attention_with_context import AttentionWithContext\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n"
     ]
    }
   ],
   "source": [
    "#config = tf.ConfigProto()\n",
    "#config.gpu_options.allow_growth = True\n",
    "print('loading data...')\n",
    "#data1 = load_csv(r'data-freeway\\10105110', 8, \"freeway\")\n",
    "#data2 = load_csv(r'data-freeway\\10105310', 8, \"freeway\")\n",
    "#data3 = load_csv(r'data-freeway\\10105510', 8, \"freeway\")\n",
    "#data4 = load_csv(r'data-freeway\\10108210', 8, \"freeway\")\n",
    "#data5 = load_csv(r'data-freeway\\10106510', 8, \"freeway\")\n",
    "#data6 = load_csv(r'data-freeway\\1095110', 8, \"freeway\")\n",
    "#data7 = load_csv(r'data-freeway\\1095510', 8, \"freeway\")\n",
    "data1 = load_csv(r'..\\temperature_data', 1, \"temperature\")\n",
    "\n",
    "# data1 = load_csv(r'data-urban/401190', 5, \"urban\")\n",
    "# data2 = load_csv(r'data-urban/401144', 7, \"urban\")\n",
    "# data3 = load_csv(r'data-urban/401413', 11, \"urban\")\n",
    "# data4 = load_csv(r'data-urban/401911', 8, \"urban\")\n",
    "# data5 = load_csv(r'data-urban/401610', 10, \"urban\")\n",
    "# data6 = load_csv(r'data-urban/401273', 8, \"urban\")\n",
    "# data7 = load_csv(r'data-urban/401137', 8, \"urban\")\n",
    "\n",
    "epoch = 50\n",
    "day = 288\n",
    "week = 2016\n",
    "seq_len = 15\n",
    "#1=5min, 3=15min, 6=30min, 12=60min\n",
    "pre_len = 12\n",
    "#data 1-7\n",
    "pre_sens_num = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train,test\n",
    "train_data, train_w, train_d, label, test_data, test_w, test_d, test_l, test_med, test_min\\\n",
    "\t= generate_data(data1, data2, data3, data4, data5, data6, data7, seq_len, pre_len, pre_sens_num)\n",
    "\n",
    "train_data = np.reshape(train_data,(train_data.shape[0], train_data.shape[1], train_data.shape[2], 1))\n",
    "train_w = np.reshape(train_w,(train_w.shape[0], train_w.shape[1], 1))\n",
    "train_d = np.reshape(train_d,(train_d.shape[0], train_d.shape[1], 1))\n",
    "\n",
    "test_data = np.reshape(test_data,(test_data.shape[0], test_data.shape[1], test_data.shape[2], 1))\n",
    "test_d = np.reshape(test_d,(test_d.shape[0], test_d.shape[1], 1))\n",
    "test_w = np.reshape(test_w,(test_w.shape[0], test_w.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME:  attention_with_context_1\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, 15, 7, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 15, 7, 15)    60          main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 15, 7, 15)    690         time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (None, 15, 105)      0           time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 15, 15)       1590        time_distributed_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 15, 15)       1860        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_1 (Atten (None, 15, 15)       255         lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "auxiliary_input_w (InputLayer)  (None, 15, 1)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "auxiliary_input_d (InputLayer)  (None, 15, 1)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 15)           1860        attention_with_context_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 15, 30)       2040        auxiliary_input_w[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 15, 30)       2040        auxiliary_input_d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer_1 (AttentionLay (None, 15)           675         lstm_2[0][0]                     \n",
      "                                                                 dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 30)           5520        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 30)           5520        bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 75)           0           attention_layer_1[0][0]          \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "                                                                 bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 20)           1520        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           210         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "main_output (Dense)             (None, 1)            11          dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 23,851\n",
      "Trainable params: 23,851\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# conv-lstm\n",
    "main_input = Input((15, 7, 1),name='main_input')\n",
    "con1 = TimeDistributed(Conv1D(filters=15, kernel_size=3, padding='same', activation='relu', strides=1))(main_input)\n",
    "con2 = TimeDistributed(Conv1D(filters=15, kernel_size=3, padding='same', activation='relu', strides=1))(con1)\n",
    "#con3 = TimeDistributed(AveragePooling1D(pool_size=2))(con2)\n",
    "con_fl = TimeDistributed(Flatten())(con2)\n",
    "con_out = Dense(15)(con_fl)\n",
    "\n",
    "lstm_out1 = LSTM(15, return_sequences=True)(con_out)\n",
    "lstm_attention = AttentionWithContext()(lstm_out1)\n",
    "lstm_out2 = LSTM(15, return_sequences=False)(lstm_attention)\n",
    "lstm_out3 = AttentionLayer()([lstm_out2, con_out])\n",
    "\n",
    "# Bilstm\n",
    "auxiliary_input_w = Input((15, 1), name='auxiliary_input_w')\n",
    "lstm_outw1 = Bidirectional(LSTM(15, return_sequences=True))(auxiliary_input_w)\n",
    "lstm_outw2 = Bidirectional(LSTM(15, return_sequences=False))(lstm_outw1)\n",
    "\n",
    "auxiliary_input_d = Input((15, 1), name='auxiliary_input_d')\n",
    "lstm_outd1 = Bidirectional(LSTM(15, return_sequences=True))(auxiliary_input_d)\n",
    "lstm_outd2 = Bidirectional(LSTM(15, return_sequences=False))(lstm_outd1)\n",
    "\n",
    "x = keras.layers.concatenate([lstm_out3, lstm_outw2, lstm_outd2])\n",
    "x = Dense(20, activation='relu')(x)\n",
    "x = Dense(10, activation='relu')(x)\n",
    "main_output = Dense(1, activation='relu', kernel_regularizer=keras.regularizers.l1_l2(0.1, 0.1), name='main_output')(x)\n",
    "model = Model(inputs = [main_input, auxiliary_input_w, auxiliary_input_d], outputs = main_output)\n",
    "model.summary()\n",
    "model.compile(optimizer='adam', loss=my_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 37676 samples, validate on 6649 samples\n",
      "Epoch 1/50\n",
      " - 12s - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 2/50\n",
      " - 13s - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 3/50\n",
      " - 13s - loss: 0.0036 - val_loss: 0.0033\n",
      "Epoch 4/50\n",
      " - 16s - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 5/50\n",
      " - 12s - loss: 0.0038 - val_loss: 0.0032\n",
      "\n",
      "Epoch 00005: val_loss improved from inf to 0.00325, saving model to model/model_0005-0.0032.h5\n",
      "Epoch 6/50\n",
      " - 11s - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 7/50\n",
      " - 15s - loss: 0.0037 - val_loss: 0.0033\n",
      "Epoch 8/50\n",
      " - 11s - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 9/50\n",
      " - 11s - loss: 0.0036 - val_loss: 0.0033\n",
      "Epoch 10/50\n",
      " - 11s - loss: 0.0036 - val_loss: 0.0035\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00325\n",
      "Epoch 11/50\n",
      " - 11s - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 12/50\n",
      " - 14s - loss: 0.0036 - val_loss: 0.0033\n",
      "Epoch 13/50\n",
      " - 14s - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 14/50\n",
      " - 11s - loss: 0.0036 - val_loss: 0.0033\n",
      "Epoch 15/50\n",
      " - 11s - loss: 0.0035 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.00325\n",
      "Epoch 16/50\n",
      " - 11s - loss: 0.0036 - val_loss: 0.0033\n",
      "Epoch 17/50\n",
      " - 10s - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 18/50\n",
      " - 10s - loss: 0.0036 - val_loss: 0.0033\n",
      "Epoch 19/50\n",
      " - 13s - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 20/50\n",
      " - 16s - loss: 0.0036 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.00325\n",
      "Epoch 21/50\n",
      " - 13s - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 22/50\n",
      " - 11s - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 23/50\n",
      " - 11s - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 24/50\n",
      " - 11s - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 25/50\n",
      " - 10s - loss: 0.0036 - val_loss: 0.0033\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.00325\n",
      "Epoch 26/50\n",
      " - 12s - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 27/50\n",
      " - 16s - loss: 0.0037 - val_loss: 0.0033\n",
      "Epoch 28/50\n",
      " - 14s - loss: 0.0035 - val_loss: 0.0033\n",
      "Epoch 29/50\n",
      " - 13s - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 30/50\n",
      " - 12s - loss: 0.0036 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.00325\n",
      "Epoch 31/50\n",
      " - 12s - loss: 0.0035 - val_loss: 0.0033\n",
      "Epoch 32/50\n",
      " - 12s - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 33/50\n",
      " - 17s - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 34/50\n",
      " - 16s - loss: 0.0035 - val_loss: 0.0050\n",
      "Epoch 35/50\n",
      " - 13s - loss: 0.0036 - val_loss: 0.0034\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.00325\n",
      "Epoch 36/50\n",
      " - 12s - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 37/50\n",
      " - 12s - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 38/50\n",
      " - 16s - loss: 0.0035 - val_loss: 0.0033\n",
      "Epoch 39/50\n",
      " - 15s - loss: 0.0035 - val_loss: 0.0033\n",
      "Epoch 40/50\n",
      " - 12s - loss: 0.0035 - val_loss: 0.0033\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.00325\n",
      "Epoch 41/50\n",
      " - 12s - loss: 0.0035 - val_loss: 0.0033\n",
      "Epoch 42/50\n",
      " - 13s - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 43/50\n",
      " - 13s - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 44/50\n",
      " - 19s - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 45/50\n",
      " - 19s - loss: 0.0037 - val_loss: 0.0033\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.00325\n",
      "Epoch 46/50\n",
      " - 13s - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 47/50\n",
      " - 13s - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 48/50\n",
      " - 11s - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 49/50\n",
      " - 13s - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 50/50\n",
      " - 14s - loss: 0.0034 - val_loss: 0.0034\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.00325\n",
      "Save model to disk\n"
     ]
    }
   ],
   "source": [
    "#train_save model\n",
    "filepath = \"model/model_{epoch:04d}-{val_loss:.4f}.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True,\n",
    "                             mode='min',period=5)\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "print('Train...')\n",
    "training_metrics = model.fit([train_data, train_w, train_d], label,\n",
    "\t\t  batch_size=128, epochs=epoch, validation_split=0.15, verbose=2,\n",
    "\t\t  class_weight='auto', callbacks=callbacks_list)\n",
    "model_json = model.to_json()\n",
    "with open(\"model/conv_lstm.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "print(\"Save model to disk\")\n",
    "\n",
    "#load model\n",
    "# with CustomObjectScope({'AttentionLayer': AttentionLayer}):\n",
    "# \tjson_file = open('model/conv_lstm.json', 'r')\n",
    "# \tloaded_model_json = json_file.read()\n",
    "# \tjson_file.close()\n",
    "# \tcnn_lstm_model = model_from_json(loaded_model_json)\n",
    "# \tcnn_lstm_model.load_weights(\"model/model_0200-0.0337.h5\", 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_size: 2016\n",
      "MAE: 12.950496581124348\n",
      "MAPE: 0.18810175983507732\n",
      "RMSE: 17.920760862040613\n"
     ]
    }
   ],
   "source": [
    "#Predict the last model\n",
    "predicted = predict_point_by_point(model, [test_data, test_w, test_d])\n",
    "p_real = []\n",
    "l_real = []\n",
    "row=2016\n",
    "for i in range(row):\n",
    "    p_real.append(predicted[i] * test_med + test_min)\n",
    "    l_real.append(test_l[i] * test_med + test_min)\n",
    "p_real = np.array(p_real)\n",
    "l_real = np.array(l_real)\n",
    "\n",
    "print (\"MAE:\", MAE(p_real, l_real))\n",
    "print (\"MAPE:\", MAPE(p_real, l_real))\n",
    "print (\"RMSE:\", RMSE(p_real, l_real))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'CUDA_VISIBLE_DEVICES'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17636\\756846644.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"CUDA_VISIBLE_DEVICES\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\Anaconda\\Installation\\envs\\deepfading\\lib\\os.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    679\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m             \u001b[1;31m# raise KeyError with the original key value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 681\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    682\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecodevalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    683\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'CUDA_VISIBLE_DEVICES'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepfading",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
